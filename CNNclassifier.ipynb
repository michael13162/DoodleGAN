{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNclassifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "74QIOZmgKZI1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Convolutional Net Categorical Image Classifier**\n",
        "\n",
        "Basic CNN for classifying a set of image doodles\n",
        "\n",
        "Setup function is below"
      ]
    },
    {
      "metadata": {
        "id": "OEu-OYEwEBwM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "a5af1ca7-cadc-4c2b-dc64-6f8a5b782d32"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.callbacks import CSVLogger\n",
        "\n",
        "GOOGLE_COLAB = True\n",
        "TRAINING_LOGS_FILE = \"/content/drive/My Drive/Colab Notebooks/\"+\"training_logs.csv\"\n",
        "MODEL_SUMMARY_FILE = \"/content/drive/My Drive/Colab Notebooks/\"+\"model_summary.txt\"\n",
        "TEST_FILE = \"/content/drive/My Drive/Colab Notebooks/\"+\"test_file.txt\"\n",
        "MODEL_FILE = \"/content/drive/My Drive/Colab Notebooks/\"+\"model.h5\"\n",
        "\n",
        "!pip install livelossplot\n",
        "from livelossplot import PlotLossesKeras"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: livelossplot in /usr/local/lib/python3.6/dist-packages (0.2.2)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from livelossplot) (5.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from livelossplot) (2.1.2)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (5.2.4)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (0.8.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (2.10)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.4.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.3.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (5.4.0)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.5.3)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.6.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (2018.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (1.14.6)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (2.3.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (1.11.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->notebook->livelossplot) (17.0.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->livelossplot) (0.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->livelossplot) (1.1.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->notebook->livelossplot) (2.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2.1->notebook->livelossplot) (4.3.0)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (3.0.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (2.1.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.4.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.2.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (1.4.2)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->notebook->livelossplot) (5.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook->livelossplot) (0.5.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (4.6.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (40.6.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (1.0.15)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.7.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.1.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jDcp08DpJBZx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**For use with Google Cloud**\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "k3fmosD_Ii9g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#from google.cloud import storage\n",
        "#client = storage.Client()\n",
        "#bucket = client.get_bucket('bucket-id-here')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vZk4QCrhK_Aw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**OR using Drive storage**"
      ]
    },
    {
      "metadata": {
        "id": "pSoSKgOeK7mi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06fde996-824e-48c2-e9b9-335247bebe8a"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive/')\n",
        "path = \"/content/drive/My Drive/Colab Notebooks/\""
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "loTiKUPmJoon",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Loading the data"
      ]
    },
    {
      "metadata": {
        "id": "LJ4fQkcWJqFh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "initial_labels = ['aircraft']\n",
        "\n",
        "labels = ['banana', 'bear', 'bird', 'cat', 'cloud', 'elephant', 'face', 'golfclub', 'hotdog']\n",
        "\n",
        "#f_path = path + \"data/\"+p+\".npy\"\n",
        "#banana_path = path + \"data/banana.npy\"\n",
        "#bear_path = path + \"data/bear.npy\"\n",
        "\n",
        "#aircraft_loaded = np.load(aircraft_path)\n",
        "#banana_loaded = np.load(banana_path)\n",
        "#bear_loaded = np.load(bear_path)\n",
        "\n",
        "f_path = path + \"data/\"+initial_labels[0]+\".npy\"\n",
        "f_loaded = np.load(f_path)\n",
        "y = np.zeros(f_loaded.shape[0])\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(f_loaded, y, test_size=0.1, random_state=42)\n",
        "\n",
        "for i, label in enumerate(labels):\n",
        "  f_path = path + \"data/\"+label+\".npy\"\n",
        "  f_loaded = np.load(f_path)\n",
        "  \n",
        "  \n",
        "  num_ex = f_loaded.shape[0]\n",
        "  \n",
        "  f_split = f_loaded[:int(num_ex/10)] \n",
        "  \n",
        "  y = np.ones(f_split.shape[0])*(i+1)\n",
        "  \n",
        "  X_train, X_test, y_train, y_test = train_test_split(f_split, y, test_size=0.1, random_state=42)\n",
        "  \n",
        "  train_X = np.concatenate((train_X, X_train), axis=0)\n",
        "  test_X = np.concatenate((test_X, X_test), axis=0)\n",
        "  train_y = np.concatenate((train_y, y_train), axis=0)\n",
        "  test_y = np.concatenate((test_y, y_test), axis=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qnDGZxYn3iLb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Run this code to save the data"
      ]
    },
    {
      "metadata": {
        "id": "I7Q1KXSD3fzf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "fadb600e-fff0-4c96-91b4-4fc9062ed4bc"
      },
      "cell_type": "code",
      "source": [
        "print('Train Size: '+ str(train_X.shape[0]))\n",
        "print('Train Label Size: '+ str(train_y.shape[0]))\n",
        "print('Test Size: '+ str(test_X.shape[0]))\n",
        "print('Test Label Size: '+ str(test_y.shape[0]))\n",
        "np.save(path+'data/train_x.npy', train_X)\n",
        "np.save(path+'data/train_y.npy', train_y)\n",
        "np.save(path+'data/test_x.npy', test_X)\n",
        "np.save(path+'data/test_y.npy', test_y)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Size: 238515\n",
            "Train Label Size: 238515\n",
            "Test Size: 26506\n",
            "Test Label Size: 26506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-zgTnBs75Wei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "4e5f6676-e129-4063-979d-4b1a7d01bda7"
      },
      "cell_type": "code",
      "source": [
        "print(str(train_X[0].shape[0]))\n",
        "print(train_X.shape)\n",
        "print(train_X[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "784\n",
            "(238515, 784)\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0  27 135  66   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  30\n",
            " 239 255 246  55   0   0   0   0   0   0   0   0 106 106  17  17  17  17\n",
            "  17  17  17  17  17  17  17  45   9  18 220 255 254  66   0   0   0   0\n",
            "   0   0   0  24 242 255 255 255 255 255 255 255 255 255 255 255 255 255\n",
            " 208  82 154 255 160   0   0   0   0   0   0   0   0 108 255 255 255 255\n",
            " 255 255 255 255 255 255 255 255 255 255 231 254 255 255 198   0   0   0\n",
            "   0   0   0   0   0  62 247 134  68  68  74  85  85  88 102 102 102 119\n",
            " 119 227 255 254 252 253 254 129  29  49 197 166  21   0   0   0  16   2\n",
            "   0   0   0   0   0   0   0   0   0   0   0  11  81 231 255 247 229 255\n",
            " 255 255 255 255 109   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0  60 255 255 235 255 232  99 228 221  40   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4 240 255\n",
            " 127 211 250  76   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0 209 255 255 194 255 159   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            " 180 255 255 152 144  34   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0  36 188 147  31   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4Mrh8HeQHO57",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Hyper Params"
      ]
    },
    {
      "metadata": {
        "id": "oWdJmx9mHNo-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 28\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT = IMAGE_SIZE, IMAGE_SIZE\n",
        "EPOCHS = 3\n",
        "BATCH_SIZE = 32\n",
        "TEST_SIZE = 30\n",
        "\n",
        "input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4qX_-RZZHXR0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Model"
      ]
    },
    {
      "metadata": {
        "id": "mG-HLXzLHcD6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(9, (3, 3), padding='same', input_shape=input_shape, activation='relu'))\n",
        "model.add(Conv2D(9, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(18, (3, 3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(18, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(36, (3, 3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(36, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(72, (3, 3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(72, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(72, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(72, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('sigmoid'))\n",
        "    \n",
        "model.compile(loss='categorical_crossentropy',\n",
        "            optimizer=RMSprop(lr=0.0001),\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "with open(MODEL_SUMMARY_FILE,\"w\") as fh:\n",
        "    model.summary(print_fn=lambda line: fh.write(line + \"\\n\"))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XrwndqC-Hpy5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Execution"
      ]
    },
    {
      "metadata": {
        "id": "K4heB8MuHq3W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "ab76d8bd-93d4-478f-bb23-4cbff032d4e5"
      },
      "cell_type": "code",
      "source": [
        "# Training\n",
        "# Convert labels to categorical one-hot encoding\n",
        "one_hot_labels = keras.utils.to_categorical(train_y, num_classes=10)\n",
        "\n",
        "num_train = train_X.shape[0]\n",
        "\n",
        "X_train = train_X.reshape((num_train, 28, 28, 1))\n",
        "\n",
        "# Train the model, iterating on the data in batches of 32 samples\n",
        "model.fit(X_train, one_hot_labels, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
        "model.save_weights(MODEL_FILE)\n",
        "\n",
        "#if GOOGLE_COLAB:\n",
        "#    files.download(MODEL_SUMMARY_FILE)\n",
        "#    files.download(MODEL_FILE)\n",
        "#    files.download(TRAINING_LOGS_FILE)\n",
        "#    files.download(TEST_FILE)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "238515/238515 [==============================] - 106s 443us/step - loss: 1.2028 - acc: 0.6102\n",
            "Epoch 2/3\n",
            "238515/238515 [==============================] - 105s 442us/step - loss: 0.7889 - acc: 0.7571\n",
            "Epoch 3/3\n",
            "238515/238515 [==============================] - 105s 439us/step - loss: 0.6958 - acc: 0.7972\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}